{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nfaces_image = np.load('../input/olivetti-faces/olivetti_faces.npy')\nfaces_target = np.load('../input/olivetti-faces/olivetti_faces_target.npy')","metadata":{"_cell_guid":"ec9b66d0-91e2-415f-941d-e55af7f9752c","_uuid":"fb886e7fc23104f72e18e15fd8b02529b1327096","collapsed":true,"jupyter":{"outputs_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#print(faces_image)\nfaces_image","metadata":{"_cell_guid":"3705828e-469d-45fe-a224-b965356a70a6","_uuid":"166e64224b658b36bfd91ac884c3bca3763af28d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_row = 64\nn_col = 64\nfaces_image.shape","metadata":{"_cell_guid":"6596da03-5a3d-45ee-9b8b-66f17725b25f","_uuid":"b7187a08057a19b6eb329040793d56b92511b856"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"faces_data = faces_image.reshape(faces_image.shape[0], faces_image.shape[1] * faces_image.shape[2])\nfaces_data.shape","metadata":{"_cell_guid":"c9e0a0cc-ee04-4d3e-915d-4637818d259a","_uuid":"974666552ad9e5c561580e4d2c80a4b6f7256596"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(faces_target)","metadata":{"_cell_guid":"4036b183-4ad8-4358-b303-83c66e0b42d6","_uuid":"2af764667fa42183c91120964b8892aa6a34996c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\nfrom skimage.io import imshow\nloadImage = faces_image[20]\nimshow(loadImage) ","metadata":{"_cell_guid":"de482bd0-aae7-4912-83b9-ec751d171f53","_uuid":"9bee57bdc968e0ce8548cd1434778ea21ff8c821"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loadImage.shape","metadata":{"_cell_guid":"527cd157-1076-4a36-919a-792915db4039","_uuid":"d0b844ecae18c232b9d6e35a5be09b3036a0ee4e"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Faces recognition using eigenfaces and SVM**","metadata":{"_cell_guid":"a8727865-9b55-45c3-b25e-a801fe0a2339","_uuid":"e4a5bebde80d6392664a4bbf288703ef7ffdda8a"}},{"cell_type":"code","source":"from __future__ import print_function\n\nfrom time import time\nimport logging\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.decomposition import PCA\nfrom sklearn.svm import SVC","metadata":{"_uuid":"56e6d8e79e1aebdd3424737f98edf8d250f3d6aa","collapsed":true,"jupyter":{"outputs_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_samples = faces_image.shape[0]\n# for machine learning we use the 2 data directly\nX = faces_data\nn_features = faces_data.shape[1]\n# the label to predict is the id of the person\ny = faces_target\nn_classes = faces_target.shape[0]","metadata":{"_uuid":"95818143b64823cde075e7e81c70586b7cfcf879","collapsed":true,"jupyter":{"outputs_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Total dataset size:\")\nprint(\"n_samples: %d\" % n_samples)\nprint(\"n_features: %d\" % n_features)\nprint(\"n_classes: %d\" % n_classes)\n","metadata":{"_uuid":"74d7277f98629852064264acc23807cee066d4d6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Xtrain, Xtest, ytrain, ytest = train_test_split(X, y)\nprint(\"Xtrain\",Xtrain)\nprint(\"Length of Xtrain:\",len(Xtrain))\nprint(\"Xtest\",Xtest)\nprint(\"Length of Xtest:\",len(Xtest))\nprint(\"ytrain\",ytrain)\nprint(\"Length of ytrain:\",len(ytrain))\nprint(\"ytest\",ytest)\nprint(\"Length of ytest:\",len(ytest))\n","metadata":{"_uuid":"020353d7713fee542af537f5fc1052807f51ef4e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compute a PCA (eigenfaces) on the olivetti dataset (treated as unlabeled\n# dataset): unsupervised feature extraction / dimensionality reduction\nn_components = 150\n\nprint(\"Extracting the top %d eigenfaces from %d faces\"\n      % (n_components, Xtrain.shape[0]))\nt0 = time()\npca = PCA(n_components=n_components, svd_solver='randomized',\n          whiten=True).fit(Xtrain)\nprint(\"done in %0.3fs\" % (time() - t0))","metadata":{"_uuid":"df69581baac6f696b9f160815c408f42352c4db8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"eigenfaces = pca.components_.reshape((n_components, n_row, n_col))\n\nprint(\"Projecting the input data on the eigenfaces orthonormal basis\")\nt0 = time()\nXtrain_pca = pca.transform(Xtrain)\nXtest_pca = pca.transform(Xtest)\nprint(\"done in %0.3fs\" % (time() - t0))\n","metadata":{"_uuid":"38a18e362703283c6ea4fcd214274fc956a29393"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train a SVM classification model\n\nprint(\"Fitting the classifier to the training set\")\nt0 = time()\nparam_grid = {'C': [1e3, 5e3, 1e4, 5e4, 1e5],\n              'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1], }\nclf = GridSearchCV(SVC(kernel='rbf', class_weight='balanced'), param_grid)\nclf = clf.fit(Xtrain_pca, ytrain)\nprint(\"done in %0.3fs\" % (time() - t0))\nprint(\"Best estimator found by grid search:\")\nprint(clf.best_estimator_)\n","metadata":{"_uuid":"327cc88ac0fa41661fef4922eabeb63b64eed79f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Quantitative evaluation of the model quality on the test set\n\nprint(\"Predicting people's names on the test set\")\nt0 = time()\ny_pred = clf.predict(Xtest_pca)\nprint(\"done in %0.3fs\" % (time() - t0))\n\nprint(classification_report(ytest, y_pred))\n","metadata":{"_uuid":"a5b41a39d5ba5767ef722c29eb3ebfbf1132d1a5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(confusion_matrix(ytest, y_pred, labels=range(n_classes)))","metadata":{"_uuid":"db40856c392a9480f4e333f4a937fb286a3b55be"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Displaying Eigenfaces\nfig, axes = plt.subplots(3, 8, figsize=(9, 4),\n                         subplot_kw={'xticks':[], 'yticks':[]},\n                         gridspec_kw=dict(hspace=0.1, wspace=0.1))\nfor i, ax in enumerate(axes.flat):\n    ax.imshow(pca.components_[i].reshape(64, 64), cmap='bone')","metadata":{"_uuid":"4987f108c42ad747faa9aabf66dca821cc703754"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loadeigen = eigenfaces[20]\nimshow(loadeigen) ","metadata":{"_uuid":"620074fc864c363bee1f37ac1b1902ed4a631ce5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot the single eigen face of the most significative eigenfaces\nimport cv2\nimg = cv2.imread('loadeigen',0)\nplt.imshow(loadeigen,cmap = 'gray', interpolation = 'bicubic')\nplt.show()","metadata":{"_uuid":"9d5b6bd83f70dcbf35449c18778fba5eba8059d8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(np.cumsum(pca.explained_variance_ratio_))\nplt.xlabel('number of components')\nplt.ylabel('cumulative explained variance');","metadata":{"_uuid":"5822b281f0c867f49d526398a12ccac406390068"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We see that these 150 components account for just over 90% of the variance. That would lead us to believe that using these 150 components, we would recover most of the essential characteristics of the data. To make this more concrete, we can compare the input images with the images reconstructed from these 150 components.","metadata":{"_uuid":"a330a044b41fbea0fb855f1da9707d7125fb60cc"}},{"cell_type":"markdown","source":"Please help with suggestions to improve this article","metadata":{"_uuid":"2c3b3f15ba1d4200ab4c43c7a3a5ba1d3a67bd4d"}}]}